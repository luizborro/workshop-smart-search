{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Busca Inteligente de Filmes\n",
        "\n",
        "Busca de filmes a partir de palavras-chave ou sentenças. O processo é composto por quatro etapas principais: i) enriquecimento de termos; busca semântica; iii) busca léxica; iv) ranqueamento.\n",
        "\n",
        "## Enriquecimento de termos\n",
        "O modelo gpt-3.5-turbo é empregado para determinar o filme que melhor corresponde aos termos fornecidos. Para esse filme, são gerados o título, sinpose curta e palavras-chave.\n",
        "\n",
        "## Busca semântica (vetorial)\n",
        "Busca vetorial por similaridade cosseno considerando embeddings gerados pelo método [sentence transformers](https://www.sbert.ne), modelo **paraphrase-multilingual-MiniLM-L12-v2**\n",
        "\n",
        "## Busca léxica\n",
        "Implementação do algoritmo BM25 disponível no Elasticsearch.\n",
        "\n",
        "## Ranqueamento\n",
        "O algoritmo Reciprocal Rank Fusion ([RRF](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf)) é empregado para ranquear os documentos oriundos das buscas semântica e léxica.\n",
        "\n"
      ],
      "metadata": {
        "id": "Tvwib_OvPHfh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Instalação de Dependências"
      ],
      "metadata": {
        "id": "-nuZStpjvIf2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1lTiknLN8TP"
      },
      "outputs": [],
      "source": [
        "!pip -q install gradio\n",
        "!pip -q install openai tiktoken langchain\n",
        "!pip -q install sentence-transformers\n",
        "!pip -q install elasticsearch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalação Local do Elasticsearch"
      ],
      "metadata": {
        "id": "M511Bzn5wNKv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bayO1OfhNgZ"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "rm -rf elasticsearch*\n",
        "wget -q https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.11.1-linux-x86_64.tar.gz\n",
        "tar -xzf elasticsearch-8.11.1-linux-x86_64.tar.gz\n",
        "sudo chown -R daemon:daemon elasticsearch-8.11.1/\n",
        "\n",
        "# only Google Colab instances\n",
        "umount /sys/fs/cgroup\n",
        "apt install cgroup-tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQYwOmlSNi_C"
      },
      "outputs": [],
      "source": [
        "%%bash --bg\n",
        "\n",
        "sudo -H -u daemon elasticsearch-8.11.1/bin/elasticsearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F06WnqJGhQ0k"
      },
      "outputs": [],
      "source": [
        "!/content/elasticsearch-8.11.1/bin/elasticsearch-setup-passwords auto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxdnjNiFNxdw"
      },
      "outputs": [],
      "source": [
        "!curl --cacert /content/elasticsearch-8.11.1/config/certs/http_ca.crt -u elastic -H 'Content-Type: application/json' -XGET https://localhost:9200/?pretty=true"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constantes\n",
        "\n",
        "Constantes relativas à configuração do Elasticsearch, além da API Key para utilização dos serviços da OpenAI."
      ],
      "metadata": {
        "id": "EatBdDmBwjKU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwOCL7QGA3cD"
      },
      "outputs": [],
      "source": [
        "#ElasticSearch CA Certificate\n",
        "CA_CERT = \"/content/elasticsearch-8.11.1/config/certs/http_ca.crt\"\n",
        "\n",
        "#ElasticSearch Password\n",
        "ELASTIC_PASSWORD = \"Elasticsearch password\"\n",
        "\n",
        "#ElasticSearch Indexes\n",
        "BM25_INDEX = \"bm25-ranking\"\n",
        "SEMANTIC_SEARCH_INDEX = \"semantic-search\"\n",
        "\n",
        "#Lexical Search Settings\n",
        "BM25_CONFIG = {\n",
        "    \"settings\": {\n",
        "      \"analysis\": {\"analyzer\": {\"default\": {\"type\": \"standard\"}}},\n",
        "      \"similarity\": {\n",
        "          \"custom_bm25\": {\n",
        "              \"type\": \"BM25\",\n",
        "              \"k1\": 2.0,\n",
        "              \"b\": 0.75,\n",
        "          }\n",
        "      },\n",
        "  },\n",
        "  \"mappings\": {\n",
        "      \"properties\": {\n",
        "          \"content\": {\n",
        "              \"type\": \"text\",\n",
        "              \"similarity\": \"custom_bm25\",  # Use the custom BM25 similarity\n",
        "          }\n",
        "      }\n",
        "  }\n",
        "}\n",
        "\n",
        "#OpenAI API Key\n",
        "OPENAI_API_KEY = \"OpenAI API Key\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo de Embedding"
      ],
      "metadata": {
        "id": "ZPmmwptNuRyA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgOqwAUQxghj"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
        "model_kwargs = {'device': 'cuda'}\n",
        "encode_kwargs = {'normalize_embeddings': False}\n",
        "hf = HuggingFaceEmbeddings(\n",
        "    model_name=model_name,\n",
        "    model_kwargs=model_kwargs,\n",
        "    encode_kwargs=encode_kwargs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ingestão do Catálogo de Filmes\n",
        "Criação dos índices no Elasticsearch para as buscas semânticas e léxicas."
      ],
      "metadata": {
        "id": "Cb8If9TFuzt_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sR2qOkjfPw6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import ElasticsearchStore\n",
        "from langchain.retrievers import ElasticSearchBM25Retriever\n",
        "from langchain_core.retrievers import BaseRetriever\n",
        "from elasticsearch import Elasticsearch\n",
        "\n",
        "\n",
        "catalog = pd.read_json('/content/drive/catalog.json')\n",
        "\n",
        "def format_catalog_row(row):\n",
        "  return f'''\n",
        "  title: {row['title']}\n",
        "  director: {row['director']}\n",
        "  year: {row['year']}\n",
        "  actors: {', '.join(row['actors'][:10])}\n",
        "  fullDescription: {row['fullDescription']}\n",
        "  genreList: {', '.join(row['genreList'])}\n",
        "  moods: {', '.join(row['moods'])}'''\n",
        "\n",
        "\n",
        "def ingest_data(es_url: str = \"https://localhost:9200\") -> list[BaseRetriever]:\n",
        "  texts = catalog.apply(lambda x: format_catalog_row(x), axis=1).to_list()\n",
        "\n",
        "  # Create an Elasticsearch client instance\n",
        "  es_client = Elasticsearch(\n",
        "      es_url,\n",
        "      ca_certs=CA_CERT,\n",
        "      basic_auth=(\"elastic\", ELASTIC_PASSWORD)\n",
        "  )\n",
        "\n",
        "  if es_client.indices.exists(index=SEMANTIC_SEARCH_INDEX):\n",
        "    es_client.indices.delete(index=SEMANTIC_SEARCH_INDEX)\n",
        "\n",
        "  vector_store = ElasticsearchStore(\n",
        "      embedding = hf,\n",
        "      index_name = SEMANTIC_SEARCH_INDEX,\n",
        "      es_connection=es_client,\n",
        "  )\n",
        "  vector_store.add_texts(texts)\n",
        "\n",
        "\n",
        "  if es_client.indices.exists(index = BM25_INDEX):\n",
        "    es_client.indices.delete(index = BM25_INDEX)\n",
        "\n",
        "  es_client.indices.create(index=BM25_INDEX, mappings=BM25_CONFIG[\"mappings\"], settings=BM25_CONFIG[\"settings\"])\n",
        "  bm25_retriver = ElasticSearchBM25Retriever(client=es_client, index_name = BM25_INDEX)\n",
        "  bm25_retriver.add_texts(texts)\n",
        "\n",
        "  return [vector_store.as_retriever(), bm25_retriver]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKGgIkilPGcx"
      },
      "outputs": [],
      "source": [
        "retrievers = ingest_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Enriquecimento de Termos"
      ],
      "metadata": {
        "id": "PmCq8gOFvVj6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GInltYj9GOPt"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.openai_functions import create_structured_output_runnable\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-3.5-turbo-1106\",\n",
        "    temperature=0,\n",
        "    openai_api_key=OPENAI_API_KEY\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"Você é uma assistente especialista em filmes.\",\n",
        "        ),\n",
        "        (\n",
        "            \"human\",\n",
        "            \"Utilize o formato provido para recomendar um filme partir da seguinte query: {query}\",\n",
        "        ),\n",
        "        (\"human\", \"Assegure-se que o filme recomendado siga o formato correto!\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "json_schema = {\"title\": \"Filme\",\n",
        "    \"description\": \"Informações básicas sobre o filme recomendado.\",\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "        \"nome\": {\"title\": \"Título\", \"description\": \"Título do filme\", \"type\": \"string\"},\n",
        "        \"sinopse\": {\"title\": \"Sinpose\", \"description\": \"sinpose curta do filme (máximo 50 caracteres)\", \"type\": \"string\"},\n",
        "        \"keywords\": {\"title\": \"Keyoword\", \"description\": \"palavras-chave descrevendo o filme (atores, diretor, gênero)\", \"type\": \"string\"}\n",
        "    },\n",
        "    \"required\": [\"title\", \"description\"],\n",
        "}\n",
        "\n",
        "query_enricher = create_structured_output_runnable(json_schema, llm, prompt)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_enricher.invoke({'query': 'arqueólogo'})"
      ],
      "metadata": {
        "id": "1i9GlD1v4Pue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Busca Híbrida\n",
        "Resultados das buscas semântica e híbrida são fundidos em uma única lista ordenada por relevância."
      ],
      "metadata": {
        "id": "LCUcA7ZdvrbM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMgg2lZpIhck"
      },
      "outputs": [],
      "source": [
        "from tqdm.asyncio import tqdm\n",
        "\n",
        "async def run_queries(queries: list[str], retrievers):\n",
        "    \"\"\"Run queries against retrievers.\"\"\"\n",
        "    tasks = []\n",
        "    query_list = []\n",
        "    for query in queries:\n",
        "        for i, retriever in enumerate(retrievers):\n",
        "            query_list.append(query)\n",
        "            tasks.append(retriever.aget_relevant_documents(query))\n",
        "\n",
        "    task_results = await tqdm.gather(*tasks)\n",
        "    results_dict = {}\n",
        "    for i, (query, query_result) in enumerate(zip(query_list, task_results)):\n",
        "        results_dict[(query, i)] = query_result\n",
        "\n",
        "    return results_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GT3cwaoWKaJ"
      },
      "outputs": [],
      "source": [
        "async def get_relevant_movies(query: str, k: int = 5):\n",
        "  movie = query_enricher.invoke({\"query\": query})\n",
        "  queries = [movie['nome'], movie['sinopse'], movie['keywords']]\n",
        "\n",
        "  results = await run_queries(queries, retrievers)\n",
        "  fused_scores = {}\n",
        "  # RRF\n",
        "  for result in results.values():\n",
        "    for rank, doc in enumerate(result):\n",
        "      if doc.page_content not in fused_scores:\n",
        "        fused_scores[doc.page_content] = 0.0\n",
        "      fused_scores[doc.page_content] += 1.0 / (rank + 60.0)\n",
        "\n",
        "  reranked_results = dict(\n",
        "      sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "  )\n",
        "  return [movie.split('\\n')[1].strip()[7:] for movie in reranked_results][:k]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intuição - Busca Semântica"
      ],
      "metadata": {
        "id": "GOaqgFrP9xgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "openai_emb = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
        "\n",
        "genres = ['terror', 'comédia', 'infantil', 'aventura', 'drama', 'documentário']\n",
        "\n",
        "df_genres = pd.concat(\n",
        "    [\n",
        "        catalog[catalog.genreList.apply(lambda x: len(x) > 0 and x[0] == genre)].sample(100)\n",
        "        for genre in genres\n",
        "    ]\n",
        ")\n",
        "df_genres = df_genres[['title', 'genreList', 'fullDescription']]\n",
        "df_genres['mainGenre'] = df_genres['genreList'].apply(lambda x: x[0])\n",
        "df_genres['embeddings'] = openai_emb.embed_documents(df_genres['fullDescription'].to_list())"
      ],
      "metadata": {
        "id": "FfE86CqG95qN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "embeddings = np.array([np.array(v) for v in df_genres['embeddings']])\n",
        "embeddings = TSNE(n_components=2).fit_transform(embeddings)\n",
        "\n",
        "df_genres['C1'] = embeddings[:, 0]\n",
        "df_genres['C2'] = embeddings[:, 1]"
      ],
      "metadata": {
        "id": "cVQaKUb8-GIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "fig = px.scatter(df_genres, x=\"C1\", y=\"C2\", color=\"mainGenre\", hover_data=['title'])\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "FTozNxp6-LUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Protótipo de Interface usando Gradio"
      ],
      "metadata": {
        "id": "eFKa_7miwKYR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeggjSatN5i3"
      },
      "outputs": [],
      "source": [
        "# Front end web app\n",
        "import gradio as gr\n",
        "\n",
        "def get_movie_card(id: str):\n",
        "  img_url = catalog.loc[id, 'image']\n",
        "  return f\"\"\"**{catalog.loc[id, 'title'].upper()}**\n",
        "   {catalog.loc[id, 'year']} • {', '.join(catalog.loc[id, 'genreList'][:5])}{\n",
        "       ' • ' +  ', '.join(catalog.loc[id, 'moods'][:5]) if len(catalog.loc[id, 'moods']) > 0 else ''}\n",
        "  **Diretor**\n",
        "  {catalog.loc[id, 'director']}\n",
        "  **Sinpose**\n",
        "   {catalog.loc[id, 'fullDescription']}\n",
        "  **Elenco**\n",
        "   {', '.join(catalog.loc[id, 'actors'][:5])}\n",
        "   ![Movie Poster]({img_url})\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.Chatbot()\n",
        "    msg = gr.Textbox()\n",
        "    clear = gr.Button(\"Clear\")\n",
        "    chat_history = []\n",
        "\n",
        "    async def user(user_message, history):\n",
        "        response = await get_relevant_movies(user_message)\n",
        "        history.append((user_message, f\"Veja se você gosta destes títulos aqui:\"))\n",
        "        for movie in response:\n",
        "          history.append((None, get_movie_card(movie)))\n",
        "\n",
        "        return gr.update(value=\"\"), history\n",
        "\n",
        "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False)\n",
        "    clear.click(lambda: None, None, chatbot, queue=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(debug=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}